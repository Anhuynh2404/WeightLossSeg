{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook này thực hiện phân đoạn (segmentation) với U-Net 3 lớp, trong đó ba lớp bao gồm tiền cảnh (foreground), hậu cảnh (background), và biên (border)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# We import all our dependencies.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from voidseg.models import Seg, SegConfig\n",
    "import numpy as np\n",
    "from csbdeep.utils import plot_history\n",
    "from voidseg.utils.misc_utils import combine_train_test_data, shuffle_train_data, augment_data\n",
    "from voidseg.utils.seg_utils import *\n",
    "from voidseg.utils.compute_precision_threshold import compute_threshold, precision\n",
    "from keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import urllib\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tải dữ liệu DSB2018.\n",
    "Từ cuộc thi Kaggle 2018 Data Science Bowl, chúng tôi sử dụng cùng một tập hợp con dữ liệu được sử dụng tại đây, bao gồm một bộ sưu tập đa dạng các nhân tế bào được chụp bằng các kính hiển vi huỳnh quang khác nhau. Chúng tôi đã trích xuất 4870 ảnh mẫu có kích thước 128×128 từ tập huấn luyện và thêm nhiễu Gaussian với giá trị trung bình là 0 và độ lệch chuẩn (sigma) lần lượt là 10 (n10), 20 (n20), và 40 (n40). Notebook này hiển thị kết quả đối với các ảnh n40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# create a folder for our data\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "# check if data has been downloaded already\n",
    "zipPath=\"data/DSB.zip\"\n",
    "if not os.path.exists(zipPath):\n",
    "    #download and unzip data\n",
    "    data = urllib.request.urlretrieve('https://owncloud.mpi-cbg.de/index.php/s/LIN4L4R9b2gebDX/download', zipPath)\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu được tải xuống ở định dạng npz, và ô dưới đây sẽ trích xuất dữ liệu huấn luyện, xác thực và kiểm tra dưới dạng mảng numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainval_data =  np.load('data/DSB/train_data/dsb2018_TrainVal40.npz')\n",
    "test_data =  np.load('data/DSB/test_data/dsb2018_Test40.npz', allow_pickle=True)\n",
    "train_images = trainval_data['X_train']\n",
    "val_images = trainval_data['X_val']\n",
    "test_images = test_data['X_test']\n",
    "\n",
    "train_masks = trainval_data['Y_train']\n",
    "val_masks = trainval_data['Y_val']\n",
    "test_masks = test_data['Y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Shape of train_images: \", train_images.shape, \", Shape of train_masks: \", train_masks.shape)\n",
    "print(\"Shape of val_images: \", val_images.shape, \", Shape of val_masks: \", val_masks.shape)\n",
    "print(\"Shape of test_images: \", test_images.shape, \", Shape of test_masks: \", test_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuẩn bị dữ liệu cho bước phân đoạn\n",
    "Tiếp theo, chúng ta chuẩn hóa toàn bộ dữ liệu thô bằng giá trị trung bình và độ lệch chuẩn (std) của train_images thô. Sau đó, chúng ta xáo trộn các ảnh huấn luyện thô và Ground Truth (GT) tương ứng. Cuối cùng, chúng ta phân chia các cặp ảnh thô và GT tương ứng để mô phỏng trường hợp không có đủ dữ liệu huấn luyện được gán nhãn. Để thực hiện việc phân chia này, hãy chỉ định tham số fraction dưới đây. Giá trị này phải nằm trong khoảng từ 0 (không bao gồm) đến 100 (bao gồm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fraction = 2 # Fraction of annotated GT and raw image pairs to use during training. \n",
    "random_seed = 1 # Seed to shuffle training data (annotated GT and raw image pairs).\n",
    "\n",
    "\n",
    "assert 0 <fraction<= 100, \"Fraction should be between 0 and 100\"\n",
    "mean, std = np.mean(train_images), np.std(train_images)\n",
    "\n",
    "X_normalized = normalize(train_images, mean, std)\n",
    "X_val_normalized = normalize(val_images, mean, std)\n",
    "X_test_normalized = normalize(test_images, mean, std)\n",
    "\n",
    "X_shuffled, Y_shuffled = shuffle_train_data(X_normalized, train_masks, random_seed = random_seed)\n",
    "X_frac, Y_frac = fractionate_train_data(X_shuffled, Y_shuffled, fraction = fraction)\n",
    "print(\"Training Data \\n..................\")\n",
    "X, Y_train_masks = augment_data(X_frac, Y_frac)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Data \\n..................\")\n",
    "X_val, Y_val_masks = augment_data(X_val_normalized, val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X = X[...,np.newaxis]\n",
    "Y = convert_to_oneHot(Y_train_masks)\n",
    "X_val = X_val[...,np.newaxis]\n",
    "Y_val = convert_to_oneHot(Y_val_masks)\n",
    "print(\"Shape of train images: \", X.shape, \", Shape of train masks: \", Y.shape)\n",
    "print(\"Shape of validation images: \", X_val.shape, \", Shape of validation masks: \", Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sl=0\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X_val[sl,...,0])\n",
    "plt.title('Raw validation image')\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(Y_val[sl,...,0])\n",
    "plt.title('1-hot encoded background')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(Y_val[sl,...,1])\n",
    "plt.title('1-hot encoded foreground')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(Y_val[sl,...,2])\n",
    "plt.title('1-hot encoded border')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cấu hình Mạng Phân đoạn\n",
    "Quá trình chuẩn bị dữ liệu cho phân đoạn đã hoàn tất. Tiếp theo, chúng ta cấu hình một mạng phân đoạn bằng cách chỉ định các tham số của SegConfig. Ví dụ, bạn có thể tăng giá trị train_epochs để đạt được kết quả tốt hơn, mặc dù điều này sẽ kéo dài thời gian tính toán. (Điều này thường đúng với giá trị fraction lớn.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "relative_weights = [1.0,1.0,5.0] # Relative weight of background, foreground and border class for training\n",
    "\n",
    "config = SegConfig(X, unet_kern_size=3, relative_weights = relative_weights,\n",
    "                   train_steps_per_epoch=400, train_epochs=3, train_loss='seg', batch_norm=True, \n",
    "                   train_batch_size=128, unet_n_first = 32, unet_n_depth=4)\n",
    "\n",
    "\n",
    "# Let's look at the parameters stored in the config-object.\n",
    "# a name used to identify the model\n",
    "model_name = 'seg_baseline'\n",
    "# the base directory in which our model will live\n",
    "basedir = 'models'\n",
    "# We are now creating our network model.\n",
    "seg_model = Seg(config, model_name, basedir=basedir)\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "seg_model.train(X, Y, (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tính ngưỡng tốt nhất trên các ảnh xác thực (để tối ưu hóa điểm Precision Trung bình). Ngưỡng này sẽ được sử dụng để tạo mặt nạ cứng (hard masks) từ các ảnh xác suất dự đoán trên các ảnh kiểm tra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "threshold=seg_model.optimize_thresholds(X_val_normalized.astype(np.float32), val_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dự đoán trên các ảnh kiểm tra để thu được kết quả phân đoạn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "predicted_images, precision_result=seg_model.predict_label_masks(X_test_normalized, test_masks, threshold)\n",
    "print(\"Average precision over all test images at IOU = 0.5: \", precision_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(predicted_images[22])\n",
    "plt.title('Prediction')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_masks[22])\n",
    "plt.title('Ground Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
